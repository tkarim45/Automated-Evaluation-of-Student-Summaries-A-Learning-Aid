{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "#from transformers import DebertaTokenizer, DebertaModel\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from argparse import Namespace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from tqdm import tqdm as tq\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The lowest classes are slaves and farmers slav...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>they sorta made people start workin...</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>An ideal tragety has three elements that make ...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     The third wave was an experimentto see how peo...  0.205683  0.380538  \n",
       "1     They would rub it up with soda to make the sme... -0.548304  0.506755  \n",
       "2     In Egypt, there were many occupations and soci...  3.128928  4.231226  \n",
       "3     The highest class was Pharaohs these people we... -0.210614 -0.471415  \n",
       "4     The Third Wave developed  rapidly because the ...  3.272894  3.219757  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171  \n",
       "7162             they sorta made people start workin... -1.408180 -0.493603  \n",
       "7163  An ideal tragety has three elements that make ... -0.393310  0.627128  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_train = pd.read_csv(\n",
    "    \"Dataset/commonlit-evaluate-student-summaries/summaries_train.csv\"\n",
    ")\n",
    "sum_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_train.prompt_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "sep = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Models/bert_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'Ġstudent', 'Ġ20', '23', '!']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn = tokenizer.tokenize(\"Hello, student 2023!\")\n",
    "tkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>len_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "\n",
       "    content   wording  len_text  \n",
       "0  0.205683  0.380538        69  \n",
       "1 -0.548304  0.506755        56  \n",
       "2  3.128928  4.231226       291  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_train[\"len_text\"] = sum_train.text.apply(\n",
    "    lambda x: len(tokenizer.tokenize(x)))\n",
    "max_len = sum_train.len_text.max()\n",
    "q_97 = sum_train.len_text.quantile(q=0.97)\n",
    "sum_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_text_token</th>\n",
       "      <th>prompt_text_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>[Chapter, Ġ13, Ġ, č, Ċ, As, Ġthe, Ġsequel, Ġto...</td>\n",
       "      <td>[1, 45642, 508, 1437, 50121, 50118, 1620, 5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>[Egypt, ian, Ġsociety, Ġwas, Ġstructured, Ġlik...</td>\n",
       "      <td>[1, 37552, 811, 2313, 21, 16697, 101, 10, 3334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>[Background, Ġ, č, Ċ, The, ĠThird, ĠWave, Ġexp...</td>\n",
       "      <td>[1, 48277, 1437, 50121, 50118, 133, 7470, 2118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>[With, Ġone, Ġmember, Ġtrim, ming, Ġbeef, Ġin,...</td>\n",
       "      <td>[1, 3908, 65, 919, 10723, 7059, 6829, 11, 10, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Egyptian society was structured like a pyramid...   \n",
       "2  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "                                   prompt_text_token  \\\n",
       "0  [Chapter, Ġ13, Ġ, č, Ċ, As, Ġthe, Ġsequel, Ġto...   \n",
       "1  [Egypt, ian, Ġsociety, Ġwas, Ġstructured, Ġlik...   \n",
       "2  [Background, Ġ, č, Ċ, The, ĠThird, ĠWave, Ġexp...   \n",
       "3  [With, Ġone, Ġmember, Ġtrim, ming, Ġbeef, Ġin,...   \n",
       "\n",
       "                                     prompt_text_ids  \n",
       "0  [1, 45642, 508, 1437, 50121, 50118, 1620, 5, 1...  \n",
       "1  [1, 37552, 811, 2313, 21, 16697, 101, 10, 3334...  \n",
       "2  [1, 48277, 1437, 50121, 50118, 133, 7470, 2118...  \n",
       "3  [1, 3908, 65, 919, 10723, 7059, 6829, 11, 10, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train = pd.read_csv(\n",
    "    \"Dataset/commonlit-evaluate-student-summaries/prompts_train.csv\"\n",
    ")\n",
    "prompts_train[\"prompt_text_token\"] = prompts_train.prompt_text.apply(\n",
    "    lambda x: tokenizer.tokenize(x)[:1200]\n",
    ")\n",
    "prompts_train[\"prompt_text_ids\"] = prompts_train.prompt_text_token.apply(\n",
    "    lambda x: [1] + tokenizer.convert_tokens_to_ids(x) + [2]\n",
    ")\n",
    "# prompts_train['prompt_q_token']=prompts_train.prompt_question.apply(lambda x: tokenizer.tokenize(x)[:1200])\n",
    "# prompts_train['prompt_q_ids']=prompts_train.prompt_q_token.apply(lambda x: [1]+tokenizer.convert_tokens_to_ids(x)+[2])\n",
    "prompts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 700)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train[\"len_prompt\"] = prompts_train.prompt_text.apply(\n",
    "    lambda x: len(tokenizer.tokenize(x))\n",
    ")\n",
    "prompts_train.len_prompt.max(), prompts_train.len_prompt.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"microsoft/deberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Models/deberta_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence(x):\n",
    "    # model.eval()\n",
    "    model.eval\n",
    "    text = torch.LongTensor(x).unsqueeze(dim=0)\n",
    "    with torch.no_grad():\n",
    "        # enc_layer, _=model(text)\n",
    "        last_layer = model(text).last_hidden_state\n",
    "        # poll_out=model(text).pooler_output\n",
    "    # return torch.mean(enc_layer[11], 1).squeeze(dim=0)\n",
    "    # return(poll_out.squeeze(dim=0))\n",
    "    return torch.mean(last_layer, 1).squeeze(dim=0)\n",
    "    # return model_seq(text).logits.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_train[\"prompt_text_sent\"] = prompts_train[\"prompt_text_ids\"].apply(\n",
    "    make_sentence\n",
    ")\n",
    "# prompts_train['prompt_q_sent']=prompts_train['prompt_q_ids'].apply(make_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_id           0\n",
       "prompt_id            0\n",
       "text                 0\n",
       "content              0\n",
       "wording              0\n",
       "len_text             0\n",
       "prompt_question      0\n",
       "prompt_title         0\n",
       "prompt_text          0\n",
       "prompt_text_token    0\n",
       "prompt_text_ids      0\n",
       "len_prompt           0\n",
       "prompt_text_sent     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_content = pd.merge(\n",
    "    sum_train, prompts_train, how=\"left\", left_on=\"prompt_id\", right_on=\"prompt_id\"\n",
    ")\n",
    "train_content.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content[\"len_ratio\"] = train_content.len_text / train_content.len_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_text_sent</th>\n",
       "      <th>len_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.098571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n",
       "      <td>0.046706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n",
       "      <td>0.392713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "\n",
       "    content   wording                                   prompt_text_sent  \\\n",
       "0  0.205683  0.380538  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   \n",
       "1 -0.548304  0.506755  [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   \n",
       "2  3.128928  4.231226  [tensor(0.0025), tensor(0.3075), tensor(-0.016...   \n",
       "\n",
       "   len_ratio  \n",
       "0   0.098571  \n",
       "1   0.046706  \n",
       "2   0.392713  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c = train_content.drop(\n",
    "    [\n",
    "        \"prompt_text\",\n",
    "        \"prompt_title\",\n",
    "        \"prompt_question\",\n",
    "        \"prompt_text_ids\",\n",
    "        \"prompt_text_token\",\n",
    "        \"len_text\",\n",
    "        \"len_prompt\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "train_c.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_text_sent</th>\n",
       "      <th>len_ratio</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n",
       "      <td>0.046706</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n",
       "      <td>0.392713</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0071d51dab6d</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would use chemicals and substances to cha...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[tensor(-0.6038), tensor(0.0009), tensor(-0.00...</td>\n",
       "      <td>0.039199</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0072b649a88c</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The Egyptian society is really different from ...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[tensor(0.0025), tensor(0.3075), tensor(-0.016...</td>\n",
       "      <td>0.121457</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>fe1e3c528e24</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave experiment developed quick...</td>\n",
       "      <td>3.020803</td>\n",
       "      <td>2.421200</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.252857</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>fe6fac61dc49</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>Mr jones started the third wave as a  expereme...</td>\n",
       "      <td>1.221089</td>\n",
       "      <td>2.269070</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>fed33a5f383e</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave gained over 200 members by the ...</td>\n",
       "      <td>2.141224</td>\n",
       "      <td>1.123777</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.238571</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>fefd4f143fbe</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed over such a short tim...</td>\n",
       "      <td>-0.782641</td>\n",
       "      <td>-0.245970</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.044286</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ff5b8d659ca6</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>Jones created a movement, which he caled \"The ...</td>\n",
       "      <td>2.049876</td>\n",
       "      <td>1.673049</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.2333), tensor(-0.01...</td>\n",
       "      <td>0.241429</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     0020ae56ffbf    ebad26   \n",
       "1     004e978e639e    3b9047   \n",
       "2     005ab0199905    3b9047   \n",
       "3     0071d51dab6d    ebad26   \n",
       "4     0072b649a88c    3b9047   \n",
       "...            ...       ...   \n",
       "7160  fe1e3c528e24    814d6b   \n",
       "7161  fe6fac61dc49    814d6b   \n",
       "7162  fed33a5f383e    814d6b   \n",
       "7163  fefd4f143fbe    814d6b   \n",
       "7164  ff5b8d659ca6    814d6b   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "0     They would rub it up with soda to make the sme... -0.548304  0.506755   \n",
       "1     In Egypt, there were many occupations and soci...  3.128928  4.231226   \n",
       "2     The highest class was Pharaohs these people we... -0.210614 -0.471415   \n",
       "3     They would use chemicals and substances to cha...  0.205683  0.380538   \n",
       "4     The Egyptian society is really different from ...  0.205683  0.380538   \n",
       "...                                                 ...       ...       ...   \n",
       "7160       The third wave experiment developed quick...  3.020803  2.421200   \n",
       "7161  Mr jones started the third wave as a  expereme...  1.221089  2.269070   \n",
       "7162  The Third Wave gained over 200 members by the ...  2.141224  1.123777   \n",
       "7163  The Third Wave developed over such a short tim... -0.782641 -0.245970   \n",
       "7164  Jones created a movement, which he caled \"The ...  2.049876  1.673049   \n",
       "\n",
       "                                       prompt_text_sent  len_ratio  split  \n",
       "0     [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   0.046706  train  \n",
       "1     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.392713  train  \n",
       "2     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.053981  train  \n",
       "3     [tensor(-0.6038), tensor(0.0009), tensor(-0.00...   0.039199  train  \n",
       "4     [tensor(0.0025), tensor(0.3075), tensor(-0.016...   0.121457  train  \n",
       "...                                                 ...        ...    ...  \n",
       "7160  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.252857    val  \n",
       "7161  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.120000    val  \n",
       "7162  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.238571    val  \n",
       "7163  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.044286    val  \n",
       "7164  [tensor(-0.1649), tensor(0.2333), tensor(-0.01...   0.241429    val  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SPLIT_SEED = 92\n",
    "\n",
    "# data_train, data_val = train_test_split(train_c, test_size=0.20, random_state=SPLIT_SEED)\n",
    "prompt_list = list(prompts_train[\"prompt_id\"])\n",
    "data_train = train_c[\n",
    "    (train_c.prompt_id == prompt_list[0])\n",
    "    | (train_c.prompt_id == prompt_list[1])\n",
    "    | (train_c.prompt_id == prompt_list[3])\n",
    "].copy()\n",
    "\n",
    "data_val = train_c[(train_c.prompt_id == prompt_list[2])].copy()\n",
    "\n",
    "data_train[\"split\"] = \"train\"\n",
    "data_val[\"split\"] = \"val\"\n",
    "data_with_split = pd.concat([data_train, data_val], ignore_index=True)\n",
    "data_with_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_df, max_seq_length):\n",
    "\n",
    "        self.text_df = text_df\n",
    "\n",
    "        self._max_seq_length = max_seq_length\n",
    "\n",
    "        self.train_df = self.text_df[self.text_df.split == \"train\"]\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.text_df[self.text_df.split == \"val\"]\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self._lookup_dict = {\n",
    "            \"train\": (self.train_df, self.train_size),\n",
    "            \"val\": (self.val_df, self.validation_size),\n",
    "        }\n",
    "\n",
    "        self.set_split(\"train\")\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._data_split = split\n",
    "        self._data_df, self._data_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._data_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = self._data_df.iloc[index]\n",
    "        text = row[\"text\"]\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        text_index = [1] + tokenizer.convert_tokens_to_ids(tokens) + [2]\n",
    "        token_index = text_index\n",
    "\n",
    "        if len(token_index) < self._max_seq_length:\n",
    "            pad = [0] * (self._max_seq_length - len(token_index))\n",
    "            token_index = token_index + pad\n",
    "\n",
    "        else:\n",
    "            token_index = token_index[: self._max_seq_length]\n",
    "\n",
    "        data_vector = torch.LongTensor(token_index)\n",
    "\n",
    "        target = row[[\"content\", \"wording\"]]\n",
    "\n",
    "        return {\n",
    "            \"x_data\": data_vector,\n",
    "            \"attention_mask\": (data_vector != 0).long(),\n",
    "            \"content_vector\": row[\"prompt_text_sent\"],\n",
    "            \"y_target\": torch.squeeze(torch.FloatTensor([target])),\n",
    "            \"len_ratio\": row[\"len_ratio\"],\n",
    "        }\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataset(data_with_split, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/qyx6hw_n0xjbkx26s_w74m000000gn/T/ipykernel_6263/290201834.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"y_target\": torch.squeeze(torch.FloatTensor([target])),\n"
     ]
    }
   ],
   "source": [
    "t = data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([350]), torch.Size([768]), torch.Size([2]), torch.Size([350]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[\"x_data\"].shape, t[\"content_vector\"].shape, t[\"y_target\"].shape, t[\n",
    "    \"attention_mask\"\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will\n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\n",
    "    )\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_batches(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/qyx6hw_n0xjbkx26s_w74m000000gn/T/ipykernel_6263/290201834.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"y_target\": torch.squeeze(torch.FloatTensor([target])),\n",
      "/var/folders/0p/qyx6hw_n0xjbkx26s_w74m000000gn/T/ipykernel_6263/290201834.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"y_target\": torch.squeeze(torch.FloatTensor([target])),\n",
      "/var/folders/0p/qyx6hw_n0xjbkx26s_w74m000000gn/T/ipykernel_6263/290201834.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"y_target\": torch.squeeze(torch.FloatTensor([target])),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 350]), torch.Size([3, 2]), torch.Size([3]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = next(gen)\n",
    "g[\"x_data\"].shape, g[\"y_target\"].shape, g[\"len_ratio\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, num_marks=2):\n",
    "        super(BertForSequenceRegression, self).__init__()\n",
    "        self.num_marks = num_marks\n",
    "        with open(\"Models/deberta_model.pkl\", \"rb\") as f:\n",
    "            self.bert = pickle.load(f)\n",
    "\n",
    "        self.hidden_1 = nn.Linear(\n",
    "            2 * config.hidden_size, 2 * config.hidden_size)\n",
    "        self.notline_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.hidden_2 = nn.Linear(2 * config.hidden_size, config.hidden_size)\n",
    "        self.notline_2 = nn.ReLU()\n",
    "\n",
    "        self.dropout_2 = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.hidden = nn.Linear(config.hidden_size, 128)\n",
    "        self.regres = nn.Linear(128, num_marks)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        content_vector,\n",
    "        token_type_ids=None,\n",
    "        attention_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        output_bert = self.bert(\n",
    "            input_ids, token_type_ids, attention_mask\n",
    "        ).last_hidden_state.mean(1)\n",
    "        h_concat = torch.cat((content_vector, output_bert), dim=1)\n",
    "        hidden_vec_1 = self.hidden_1(h_concat)\n",
    "        hidden_drop_1 = self.dropout_1(hidden_vec_1)\n",
    "        hidden_vecn_1 = self.notline_1(hidden_drop_1)\n",
    "        hidden_vec_2 = self.hidden_2(hidden_vecn_1)\n",
    "        hidden_drop_2 = self.dropout_2(hidden_vec_2)\n",
    "        hidden_vecn_2 = self.notline_2(hidden_drop_2)\n",
    "        hidden = self.hidden(hidden_vecn_2)\n",
    "        marks = self.regres(hidden)\n",
    "\n",
    "        return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(hidden_dropout_prob=0.05, hidden_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceRegression(\n",
       "  (bert): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (hidden_1): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "  (notline_1): ReLU()\n",
       "  (dropout_1): Dropout(p=0.05, inplace=False)\n",
       "  (hidden_2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  (notline_2): ReLU()\n",
       "  (dropout_2): Dropout(p=0.05, inplace=False)\n",
       "  (hidden): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (regres): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Score: -0.7733938694000244\n",
      "Wording Score: -0.7640351057052612\n",
      "Positive Content Score: 0.3157454018473356\n",
      "Positive Wording Score: 0.31777084289582486\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# from transformers import BertTokenizer, BertForSequenceRegression\n",
    "\n",
    "# Define the device to be CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the tokenizer using pickle\n",
    "with open(\"Models/bert_tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load the trained model\n",
    "model = BertForSequenceRegression().cpu()  # Ensure model is on CPU\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"Models/deb_model_3.pt\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a test summary\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_index = (\n",
    "    [tokenizer.cls_token_id]\n",
    "    + tokenizer.convert_tokens_to_ids(tokens)\n",
    "    + [tokenizer.sep_token_id]\n",
    ")\n",
    "\n",
    "# Pad or truncate the token index\n",
    "max_length = 260\n",
    "if len(token_index) < max_length:\n",
    "    pad = [tokenizer.pad_token_id] * (max_length - len(token_index))\n",
    "    token_index = token_index + pad\n",
    "else:\n",
    "    token_index = token_index[:max_length]\n",
    "\n",
    "# Convert token index to tensor\n",
    "data_vector = torch.LongTensor(token_index).unsqueeze(dim=0).to(device)\n",
    "\n",
    "# Generate content vector (random for illustration)\n",
    "content_vector = torch.randn(1, 768).to(device)\n",
    "\n",
    "# Generate attention mask\n",
    "attention_mask = (data_vector != 0).long()\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    scores = model(data_vector, content_vector, attention_mask=attention_mask)\n",
    "\n",
    "# Parse the output tensor to extract content and wording scores\n",
    "content_score, wording_score = scores[:, 0], scores[:, 1]\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Content Score:\", content_score.item())\n",
    "print(\"Wording Score:\", wording_score.item())\n",
    "\n",
    "\n",
    "def convert_to_positive(score):\n",
    "    \"\"\"\n",
    "    Converts a score to a positive value between 0 and 1.\n",
    "\n",
    "    Args:\n",
    "        score: The score to convert.\n",
    "\n",
    "    Returns:\n",
    "        The converted score.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-score))\n",
    "\n",
    "\n",
    "# Convert content and wording scores to positive values\n",
    "positive_content_score = convert_to_positive(content_score.item())\n",
    "positive_wording_score = convert_to_positive(wording_score.item())\n",
    "\n",
    "# Print the converted scores\n",
    "print(\"Positive Content Score:\", positive_content_score)\n",
    "print(\"Positive Wording Score:\", positive_wording_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
